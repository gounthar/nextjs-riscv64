= When Your Binary Builds But Next.js Won't Use It: The riscv64 Platform Detection Story
Bruno Verachten
v1.0, 2025-11-15
:description: After successfully compiling native @next/swc binaries for riscv64, I discovered Next.js won't use them—not due to technical issues, but because of hardcoded platform checks that ignore entire processor architectures
:keywords: nextjs, riscv64, swc, rust, platform detection, native modules, compilation
:imagesdir: ./images
:source-highlighter: rouge
:toc: left
:toclevels: 2
:sectnums:
:icons: font

[abstract]
After 77 minutes of watching cargo compile hundreds of Rust crates, I had a perfectly valid 210MB native SWC binary for riscv64. I packaged it correctly, placed it exactly where Next.js expects platform-specific binaries, and ran the build. Next.js used the WASM fallback anyway—not because my binary was broken, but because riscv64 doesn't exist in a hardcoded JavaScript platform map. This is the story of solving every technical challenge only to be blocked by a missing entry in an object literal.

== The Victory Lap That Wasn't

In my previous session, I'd documented the entire build process, navigated the ring v0.16.20 cryptography blocker, and discovered the `--no-default-features` workaround. I'd left the build running, and when I came back, I had success:

[source,bash]
----
$ ls -lh ~/next.js/target/release/libnext_swc_napi.so
-rwxr-xr-x 1 poddingue poddingue 210M Nov 14 23:31 libnext_swc_napi.so
----

210 megabytes of native Rust code, compiled specifically for riscv64. The build had taken 77 minutes of wall-clock time, compiling hundreds of crates across 8 cores. This was the breakthrough I needed.

Or so I thought.

== The Packaging Process

Next.js expects SWC binaries to be published as optional dependencies with platform-specific package names. The naming convention follows this pattern:

[source,text]
----
@next/swc-{platform}-{architecture}-{abi}
----

For my riscv64 Linux system, that translates to `@next/swc-linux-riscv64-gnu`.

I created the package structure manually:

[source,bash]
----
mkdir -p node_modules/@next/swc-linux-riscv64-gnu
cp ~/next.js/target/release/libnext_swc_napi.so \
   node_modules/@next/swc-linux-riscv64-gnu/next-swc.linux-riscv64-gnu.node
----

NOTE: Cargo builds a `.so` file (standard Linux shared library), but Node.js native modules use the `.node` extension by convention. It's the same format—just a different extension for Node.js's module loader.

Then I created the `package.json`:

[source,json]
----
{
  "name": "@next/swc-linux-riscv64-gnu",
  "version": "13.5.6",
  "main": "next-swc.linux-riscv64-gnu.node",
  "files": [
    "next-swc.linux-riscv64-gnu.node"
  ],
  "os": ["linux"],
  "cpu": ["riscv64"],
  "engines": {
    "node": ">= 10"
  }
}
----

This mirrors exactly what Vercel publishes for official platforms like `@next/swc-linux-x64-gnu`. Same structure, same metadata, just a different architecture.

I verified the setup:

[source,bash]
----
$ ls -la node_modules/@next/swc-linux-riscv64-gnu/
total 210M
drwxr-xr-x 2 poddingue poddingue   60 Nov 14 23:45 .
drwxr-xr-x 3 poddingue poddingue   80 Nov 14 23:44 ..
-rw-r--r-- 1 poddingue poddingue  232 Nov 14 23:45 package.json
-rwxr-xr-x 1 poddingue poddingue 210M Nov 14 23:45 next-swc.linux-riscv64-gnu.node
----

Perfect. Binary in place, package.json present, file permissions correct. Time to test.

== The Test That Should Have Worked

I had a simple Next.js 13.5.6 Pages Router test app ready. To force Next.js to use SWC instead of the Babel fallback, I removed the `.babelrc` file:

[source,bash]
----
mv .babelrc .babelrc.backup
----

Then I ran the build:

[source,bash]
----
$ npm run build

> test-app@1.0.0 build
> next build

info  - Linting and checking validity of types
info  - Creating an optimized production build
----

And here's where I noticed something odd. The build was taking too long. If it were using native SWC, the compilation phase should be nearly instantaneous. But it was slow. Really slow.

I checked the detailed build output and saw the telltale signs of WASM usage—the same slow compilation patterns I'd seen with the Babel fallback.

Next.js wasn't using my native binary. It was falling back to the WASM implementation of SWC.

== The Investigation

First, I double-checked everything:

*Binary validity*:
[source,bash]
----
$ file node_modules/@next/swc-linux-riscv64-gnu/next-swc.linux-riscv64-gnu.node
next-swc.linux-riscv64-gnu.node: ELF 64-bit LSB shared object, UCB RISC-V,
version 1 (SYSV), dynamically linked, with debug_info, not stripped
----

Correct format. Correct architecture. Definitely a valid shared library.

*Package structure*:
[source,bash]
----
$ cat node_modules/@next/swc-linux-riscv64-gnu/package.json
{
  "name": "@next/swc-linux-riscv64-gnu",
  "version": "13.5.6",
  "main": "next-swc.linux-riscv64-gnu.node"
}
----

Looks right. Matches the official package structure.

*Node.js can load it*:
[source,bash]
----
$ node -e "console.log(require('./node_modules/@next/swc-linux-riscv64-gnu/next-swc.linux-riscv64-gnu.node'))"
[Object: null prototype] { ... }  # Successfully loaded!
----

So Node.js could load the binary directly. The module was valid. Why wasn't Next.js using it?

== The Platform Detection Code

I cloned the Next.js repository and started reading the source code, specifically looking for how Next.js decides which SWC binary to load.

The relevant code is in `packages/next/src/build/swc/index.ts`:

[source,typescript]
----
function loadWasm(isDevelopment) {
  // ... WASM loading code
}

async function loadBinding(useWasm) {
  if (useWasm) {
    return loadWasm(...)
  }

  // Try to load native binding
  return loadNative()
}
----

But the real logic is in how Next.js determines whether to use WASM or native bindings. That happens earlier, in the platform detection code.

I found it in the binary loading utility:

[source,typescript]
----
const ArchName = {
  'x64': 'x64',
  'arm64': 'arm64',
  'ia32': 'ia32'
}

const PlatformName = {
  'win32': 'win32',
  'darwin': 'darwin',
  'linux': 'linux'
}

const triples = [
  {
    platform: PlatformName[process.platform],
    arch: ArchName[process.arch],
    abi: 'gnu',
    platformArchABI: `${PlatformName[process.platform]}-${ArchName[process.arch]}-gnu`,
  }
]
----

Look at that `ArchName` object. See what's missing?

[source,typescript]
----
'riscv64': 'riscv64'
----

On my Banana Pi F3, `process.arch` returns `'riscv64'`. But `ArchName['riscv64']` is `undefined`. So the code constructs a platform triple with `undefined` as the architecture, realizes something is wrong, and falls back to WASM.

My binary was never even attempted. Next.js decided before looking at the filesystem that riscv64 binaries couldn't possibly exist.

== The Frustration of Artificial Restrictions

This is the kind of blocker that makes you want to throw your keyboard across the room.

I spent:

* Hours navigating Rust dependency chains
* More hours figuring out the ring v0.16.20 workaround
* 77 minutes watching compilation
* Time carefully packaging the binary
* Time verifying it was valid and loadable

And the actual blocker was a JavaScript object that doesn't include `'riscv64'` as a key.

It's not even a difficult fix. It's literally:

[source,typescript]
----
const ArchName = {
  'x64': 'x64',
  'arm64': 'arm64',
  'ia32': 'ia32',
  'riscv64': 'riscv64'  // ADD THIS LINE
}
----

But here's the thing: this isn't a bug. It's defensive programming. The code assumes "if Vercel doesn't officially publish binaries for an architecture, they don't exist, so don't bother checking."

For Vercel's official releases, that's a perfectly reasonable assumption. They control the build pipeline, they know what they publish, and they can hardcode the supported platforms.

But it prevents exactly the kind of community-driven porting work I'm doing. Someone building custom binaries for an unsupported platform has no way to make Next.js use them without patching Next.js itself.

== Alternative Build Command: native-tls Feature

After discussing the ring blocker in Issue #9, I realized there was another approach beyond `--no-default-features`. The SWC Cargo.toml actually has a `native-tls` feature that's mutually exclusive with `rustls-tls`.

I tried rebuilding with explicit features:

[source,bash]
----
cargo build --release \
  --manifest-path crates/napi/Cargo.toml \
  --no-default-features \
  --features native-tls,napi
----

This approach:

* ✅ Avoids ring (uses system OpenSSL instead)
* ✅ Keeps all necessary features (NAPI bindings)
* ✅ More explicit about what's enabled
* ⚠️ Links against system OpenSSL (fine for Debian with updated packages)

The build completed successfully with the same 77-minute runtime and 210MB output. This confirms that the native-tls approach is viable and doesn't sacrifice functionality needed for SWC transformation.

== The Path Forward

I see a few options:

=== Option 1: Local Patch

I can modify Next.js's platform detection code locally:

[source,typescript]
----
const ArchName = {
  'x64': 'x64',
  'arm64': 'arm64',
  'ia32': 'ia32',
  'riscv64': 'riscv64'
}
----

This works for testing but requires patching every Next.js installation. Not sustainable for distribution.

=== Option 2: Upstream Engagement

The real solution is engaging with the Next.js team. I could:

. Open an issue explaining the situation
. Propose more permissive detection (check filesystem first, fall back only if binary is missing)
. Offer to help with CI integration for riscv64
. Share benchmarks and test results

The benefit: helps not just riscv64, but any future architecture someone wants to port to (loongarch64, anyone?).

=== Option 3: Maintained Fork

As a last resort, I could maintain a fork of Next.js with:

* riscv64 added to platform detection
* CI builds for riscv64 binaries
* Published packages for easy consumption

This is the most work but gives the community a turnkey solution while waiting for upstream support.

=== Option 4: Try Next.js 14+

Maybe newer versions are more flexible? Worth investigating. The trade-off is that Next.js 14+ has different features and might have other compatibility issues on riscv64.

== Lessons Learned

=== Building ≠ Loading ≠ Using

This session taught me to be much more precise about validation:

* *Building*: Can I compile the code? ✅
* *Loading*: Can the runtime load the binary? ✅ (verified with `node -e "require(...)"`)
* *Using*: Does the application actually use it? ❌ (platform check blocks it)

I validated the first two but assumed the third. That assumption cost me debugging time.

=== Platform Detection Is Often The Real Blocker

In retrospect, I should have checked Next.js's binary loading code *before* spending 77 minutes compiling. I assumed that if I built a valid binary and placed it correctly, Next.js would use it.

But artificial restrictions—platform whitelists, architecture maps, hardcoded assumptions—can block you just as effectively as technical incompatibilities.

When porting to new platforms, expect to spend as much time fighting arbitrary restrictions as actual technical problems.

=== Feature Flags Are Powerful

The ability to swap `rustls-tls` for `native-tls` via Cargo features continues to be a lifesaver. It let me work around the ring blocker without waiting for upstream dependency updates.

When working with Rust projects, always check `Cargo.toml` for available features. They often provide escape hatches for platform-specific issues.

=== Documentation Pays Off

I created comprehensive documentation in `docs/BUILDING-SWC.md` covering:

* The full build process
* The ring workaround
* Feature flag options
* Packaging instructions
* Testing procedures

This documentation is now invaluable because it captures the *successful* build process. Even though Next.js won't use the binary yet, I know the compilation works and I don't have to rediscover the workarounds.

== What's Next

In the next session, I plan to:

. *Patch Next.js 13.5.6 locally* to add riscv64 to the platform map
. *Test thoroughly* with both Pages Router and App Router
. *Measure performance* vs Babel fallback (expecting 15-20x improvement)
. *Test Next.js 14* to see if platform detection is more flexible
. *Engage upstream* with findings and proposals

I'll also update:

* Issue #1 (Runtime Testing) with native SWC results
* PR #8 comments about the platform detection blocker
* README.md with current status

== Build Metrics

For reference, here are the complete build metrics from this session:

[cols="1,2"]
|===
|Metric |Value

|Build Duration
|77 minutes

|Output Size
|210MB

|Cargo Command
|`cargo build --release --no-default-features --features native-tls,napi`

|Target Platform
|riscv64gc-unknown-linux-gnu

|Rust Version
|1.91.1 + nightly-2023-10-06

|Hardware
|Banana Pi F3 (8 cores, 15GB RAM)

|OS
|Debian 13 (Trixie)

|Next.js Version
|13.5.6
|===

== Session Work Summary

This session included:

. Updated CLAUDE.md structure and synced to config repository
. Responded to PR #8 review comments via pr-review-responder agent
. Updated Issues #1 and #9 with status
. Completed SWC native build (77 minutes, 210MB)
. Tested binary loading and packaging
. Discovered Next.js platform detection blocker
. Investigated Next.js source code to identify root cause
. Documented findings and next steps

== Conclusion

After 77 minutes of compilation, I have a working native @next/swc binary for riscv64. It builds cleanly using the `--no-default-features --features native-tls` flags to avoid the ring dependency blocker. The output is a valid Node.js native module that loads successfully.

The only problem? Next.js 13.5.6 won't use it because riscv64 isn't in a hardcoded architecture map.

This is peak software development: solve complex technical problems (Rust cross-platform compilation, cryptography library compatibility, NAPI bindings) only to be blocked by a missing entry in a JavaScript object.

But here's the positive spin: we know exactly what the blocker is, we know exactly how to fix it, and we have a clear path forward. The build process works. The binary is valid. The platform detection is patchable.

The riscv64 Next.js ecosystem is getting closer to parity with mainstream architectures, one hardcoded platform check at a time.

Now to go patch that platform map and finally see what this native binary can do.

---

_This work is part of the nextjs-riscv64 project, bringing modern web development tools to RISC-V architecture. All code, documentation, and build guides are available at https://github.com/gounthar/nextjs-riscv64._

_Hardware: Banana Pi F3 running Debian 13 (Trixie) with Node.js v24.11.1 from the unofficial-builds project._
